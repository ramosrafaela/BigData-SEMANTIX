# BigData-SEMANTIX

<br>
<p align="center">
  <img src="https://github.com/ramosrafaela/BigData-SEMANTIX/figures/semantixlogo.png" />
</p>

<h1 align="center"> BigData Science - SEMANTIX  </h1>

![Badge concluded](http://img.shields.io/static/v1?label=STATUS&message=ONGOING&color=GREEN&style=for-the-badge)

Aqui irei subir todos os exercícios que realizei ao longo da trilha de BigData Science oferecido pela SEMANTIX. O conteudo pragmático da trilha é dado por:

``Big Data Foundations (Semana 1, 2 e 3):``

• Conhecimento de ferramentas atuais no mercado de Big Data;
• Criação e funcionamento de um cluster Hadoop para Big Data em Docker;
• Manipulação de dados com HDFS;  
• Manipulação de dados com uso do Hive;
• Otimização de consultas em grandes volumes de dados estruturados e semiestruturados com uso de Hive;
• Ingestão de dados relacionais para o HDFS/Hive, com uso do Sqoop;
• Otimização de importação no Sqoop;
• Exportação de dados do HDFS para o SGBD, com uso do Sqoop;
• Manipulação de dados com HBase;
• Operações com Dataframe em Spark para processamento de dados em batch;
• Uso do Spark SQL Queries para consultas de dados estruturados e semiestruturados.


``Armazenamento e escrita de dados (Semana 4):``

• MongoDB:
  • Entendimento de conceitos e arquitetura NoSQL e MongoDB;
  • Instalação de cluster MongoDB através de container e Cloud;
  • Realizar pesquisas no MongoDB com diferentes operadores;
• Redis:
  • Entendimento de conceitos e arquitetura NoSQL e Redis;
  • Instalação de cluster Redis através de container;
  • Entendimento de diversos tipos de estrutura de dados com Redis-CLI;
• Kafka:
  • Entendimento de conceitos e arquitetura do Kafka e da Confluent;
  • Instalação de cluster Kafka através de container;
  • Gerenciamento de tópicos;
  • Produção e consumo de dados através do console;
  • Entendimento das guias do Control Center.
• Elastic:
  • Entendimento de conceitos e arquitetura da Elastic;
  • Instalação de cluster Elastic através de container;
  • Realizar operações de CRUD em índices;
  • Entendimento das guias do Kibana.

``Python (Semana 5 e 6)``

• Os fundamentos de python como linguagem de programação
• Pacote Anaconda para distribuição de python
• Desevolvimento em web-browser usando Jupyter
• Criação e uso de virtual enviroments
• Uso de Orientado Objeto com python
• Criando Funções e isolamento em módulos
• Criando Modulos e importando
• Criando Testes automatizados
• Registros ao longo do código usando logs
• Decorators para modificar comportamento de funções
• Uso plotly para gerar gráficos
• Usando pandas para malipular dados
• Boas Praticas de programação
• Os principios S.O.L.I.D.

``PySpark (Semana 7)``
• Fundamentos
• Manipulação de Big Data
• Uso do Jupyter Notebooks para a criação de projetos em Spark com Python
• Spark batch intermediario
• Operações com RDD em Spark para processamento de dados em batch;
• Uso de Partições com RDD;
• Operações com Dataset em Spark para processamento de dados em batch;
• Uso de Dataset em Dataframe e RDD;
• Comandos avançados com Dataset;

``Estatística Descritiva (Semana 8)``

• Aplicando medidas de dispersão (Média, Mediana, Moda, Quartis, Desvio padrão e variância) para descrever dados
• Usando correlação e covariância para descrever relações entre features
• Histograma para descrever distribuição de dados
• Probabilidade de eventos simples
• Teorema de Bayes aplicado a raciocinico de inferência
• Amostragem para representatividade estatisitica
• Apresentação de Distribuição de Probabilidade
• O uso de Likelihood

``Machine Learning (Semana 9)``

• Uso de algoritmos de clusterização (K-Means, etc...)
• Uso de algoritmos de classificação (SVM, etc)
• Implementação de regressão (Regressão linear)

``Redes Neurais (Semana 10)``
• Fundamentos de Redes Neurais
• Uso básico de PyTorch
• Uso básico de Keras
• Uso básico de Tensor Flow

``Processamento de Linguagem Natural (Semana 11)``
• Fundamentos de NLP moderno
• Uso de TF-IDF
• Composição WORD2VEC
• Bag of Word para processamento de texto
• Metódos baseados em Redes Neurais

``Algoritmos Genéticos (Semana 12)``
• Conceitos de AG
• Problema básico AG
• Aplicações
• Desenvolvimento em Python
• Bibliotecas de AG


## ✔️ Techniques and technologies used

- ``Hadoop``
- ``Redis``
- ``Spark``
- ``SQL``
- ``python``
- ``jupyter notebook```
